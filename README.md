# ğŸ¥ Hospital Readmission Prediction Using Machine Learning

This project predicts whether a patient is likely to be **readmitted within 30 days** using the **Diabetes 130-US Hospitals Dataset**.  
It applies real-world data preprocessing, class-imbalance handling, and a tuned **XGBoost classifier**, then exposes the model via an interactive **Streamlit app**.

---

## ğŸ“Œ Project Overview

Hospital readmissions are costly, risky, and heavily monitored.  
This project builds a machine learning pipeline to:

âœ… Clean and preprocess clinical records  
âœ… Encode categorical + numerical features  
âœ… Handle severe class imbalance  
âœ… Train an XGBoost model  
âœ… Evaluate its performance  
âœ… Provide an easy-to-use prediction UI (Streamlit)

The final model predicts whether a patient will be **readmitted within 30 days** (1 = Yes, 0 = No).

---

## ğŸ“ Dataset Description

**Dataset:** *Diabetes 130-US Hospitals for 1999â€“2008*  
**Source:** UCI Machine Learning Repository  

It contains more than **100,000 patient encounters**, including:

- Patient demographics  
- Diagnoses  
- Lab results  
- Medications  
- Hospital stay details  
- Readmission outcome (`<30`, `>30`, or `NO`)  

For this assignment, the target variable was converted to:

- **1 â†’ Readmitted within 30 days**
- **0 â†’ Not readmitted**

---

## ğŸ§¹ Data Preprocessing Steps

1. Replace missing placeholders `"?"` with `NaN`  
2. Drop irrelevant columns:
   - `weight`
   - `patient_nbr`
3. Convert the target column:
   ```python
   df["readmitted"] = df["readmitted"].apply(lambda x: 1 if x == "<30" else 0)

Separate features (X) and labels (y)

Build a preprocessing pipeline:

SimpleImputer for missing values

StandardScaler for numeric features

OneHotEncoder for categorical features

âš–ï¸ Handling Class Imbalance

The dataset is extremely imbalanced:

88% = Not readmitted

12% = Readmitted

To fix this, the project applies:

âœ… SMOTE oversampling (after encoding)
âœ… scale_pos_weight in XGBoost
âœ… Tuned hyperparameters for better recall

This dramatically improved model sensitivity.

ğŸ¤– Model Used â€” XGBoost Classifier
Key hyperparameters:

XGBClassifier(
    n_estimators=300,
    max_depth=6,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=10,
    eval_metric="logloss",
    random_state=42
)

âœ… Model Performance
Metric	Score
Accuracy	~0.50
Precision	~0.15
Recall	~0.76 âœ…
F1-Score	~0.25
âœ… Why low accuracy is acceptable here?

Because the dataset is heavily imbalanced, accuracy is misleading.
A model that always predicts "NO" would score 88% accuracy but be useless.

Recall is the main goal â€” catch as many risky patients as possible.
Your modelâ€™s recall of 0.76 is very strong for this dataset.

ğŸ“¸ Project Screenshots
âœ… 1. Streamlit Home

(Insert image here)
![Streamlit Home](images/streamlit_home.png)

âœ… 2. Prediction Form

(Insert image here)
![Prediction Page](images/prediction_form.png)

âœ… 3. Prediction Result

(Insert image here)
![Prediction Output](images/prediction_output.png)

You can upload screenshots later â€” placeholders are already included.

ğŸ”§ How to Run the Project
âœ… 1. Install dependencies
pip install -r requirements.txt

âœ… 2. Train the model
python src/model.py


This will generate:

models/trained_model.pkl

âœ… 3. Run Streamlit

Make sure you're inside the streamlit_app folder:

cd streamlit_app
streamlit run app_streamlit.py

ğŸ“‚ Project Structure
AiWk5/
â”‚â”€â”€ data/
â”‚   â””â”€â”€ readmission.csv
â”‚
â”‚â”€â”€ models/
â”‚   â””â”€â”€ trained_model.pkl
â”‚
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â””â”€â”€ model.py
â”‚
â”‚â”€â”€ streamlit_app/
â”‚   â””â”€â”€ app_streamlit.py
â”‚
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt

âœ… Features Implemented

âœ… End-to-end ML pipeline

âœ… Clean and structured code

âœ… Well-commented Python scripts

âœ… Automatic preprocessing

âœ… XGBoost classifier

âœ… Class imbalance handling

âœ… Streamlit UI

âœ… Model saving / loading

ğŸ“ License

This project is for academic use under the course ML Assignment (Part 2: Case Study).

ğŸ‘¨â€ğŸ’» Author

Meshack Odhiambo Oluoch
Bachelor of Information Technology
Masinde Muliro University of Science & Technology